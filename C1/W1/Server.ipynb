{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPsUYTxaaW6qEDS1r2zwEd0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miragecore/MLOps_Coursera/blob/develop/C1/W1/Server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "대단한 내용은 없다 서버 만들기 연습인듯"
      ],
      "metadata": {
        "id": "cwM0ZoSRqXrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "구글 드라이브 마운트"
      ],
      "metadata": {
        "id": "0EwMCeBFkxFF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SyLQsONSHfy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#!mkdir -p /drive\n",
        "#umount /drive\n",
        "#!mount --bind /content/drive/MyDrive /drive\n",
        "#!mkdir -p /drive/ngrok-ssh\n",
        "#!mkdir -p ~/.ssh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "구글 드라이브에 폴더 생성  \n",
        "깃허브에서 구글 워크 드라이브로 requirements.txt 복사해서 환경 구성"
      ],
      "metadata": {
        "id": "TVS_zgVNkyuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "root_path = '/content/drive/MyDrive'\n",
        "paths = ['MLOps_Coursera', 'ML_for_Production', 'Course1', 'Week1']\n",
        "\n",
        "os.chdir(root_path)\n",
        "\n",
        "for folder in paths:\n",
        "  if not os.path.isdir(folder):\n",
        "    os.mkdir(folder)\n",
        "    print('mkdir {folder}')\n",
        "  os.chdir(folder)\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "#강좌에서 제공하는 requirements대로 설치하면 호환성에 문제가 생겨서 Requirements 수정\n",
        "!wget https://raw.githubusercontent.com/Miragecore/MLOps_Coursera/develop/C1/W1/requirements.txt -O requirements.txt\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "5X44Nph-cx0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display"
      ],
      "metadata": {
        "id": "jGUACuQ3Wtx1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "필요한 파일은 구글드라이브에 미리 올려둔다.  \n",
        "/images\n"
      ],
      "metadata": {
        "id": "SG2xeBsplpmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some example images\n",
        "image_files = [\n",
        "    'apple.jpg',\n",
        "    'clock.jpg',\n",
        "    'oranges.jpg',\n",
        "    'car.jpg'\n",
        "]\n",
        "\n",
        "for image_file in image_files:\n",
        "    print(f\"\\nDisplaying image: {image_file}\")\n",
        "    display(Image(filename=f\"images/{image_file}\"))"
      ],
      "metadata": {
        "id": "E1uAdq_EW41f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_name = \"images_with_boxes\"\n",
        "if not os.path.exists(dir_name):\n",
        "    os.mkdir(dir_name)"
      ],
      "metadata": {
        "id": "bEShcBfoYTwu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "import cvlib as cv\n",
        "from cvlib.object_detection import draw_bbox\n",
        "\n",
        "\n",
        "def detect_and_draw_box(filename, model=\"yolov3-tiny\", confidence=0.5):\n",
        "    \"\"\"Detects common objects on an image and creates a new image with bounding boxes.\n",
        "\n",
        "    Args:\n",
        "        filename (str): Filename of the image.\n",
        "        model (str): Either \"yolov3\" or \"yolov3-tiny\". Defaults to \"yolov3-tiny\".\n",
        "        confidence (float, optional): Desired confidence level. Defaults to 0.5.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Images are stored under the images/ directory\n",
        "    img_filepath = f'images/{filename}'\n",
        "    \n",
        "    # Read the image into a numpy array\n",
        "    img = cv2.imread(img_filepath)\n",
        "    \n",
        "    # Perform the object detection\n",
        "    bbox, label, conf = cv.detect_common_objects(img, confidence=confidence, model=model)\n",
        "    \n",
        "    # Print current image's filename\n",
        "    print(f\"========================\\nImage processed: {filename}\\n\")\n",
        "    \n",
        "    # Print detected objects with confidence level\n",
        "    for l, c in zip(label, conf):\n",
        "        print(f\"Detected object: {l} with confidence level of {c}\\n\")\n",
        "    \n",
        "    # Create a new image that includes the bounding boxes\n",
        "    output_image = draw_bbox(img, bbox, label, conf)\n",
        "    \n",
        "    # Save the image in the directory images_with_boxes\n",
        "    cv2.imwrite(f'images_with_boxes/{filename}', output_image)\n",
        "    \n",
        "    # Display the image with bounding boxes\n",
        "    display(Image(f'images_with_boxes/{filename}'))"
      ],
      "metadata": {
        "id": "Q9sT2kPwYkZE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_file in image_files:\n",
        "    detect_and_draw_box(image_file)"
      ],
      "metadata": {
        "id": "AXTTmBSaYquU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_and_draw_box(\"fruits.jpg\")"
      ],
      "metadata": {
        "id": "dPAaNZDTZJB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_and_draw_box(\"fruits.jpg\", confidence=0.3)"
      ],
      "metadata": {
        "id": "SZcoyh0lZZ_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_name = \"images_uploaded\"\n",
        "if not os.path.exists(dir_name):\n",
        "    os.mkdir(dir_name)"
      ],
      "metadata": {
        "id": "a3r7FHn_Zh02"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import uvicorn\n",
        "import numpy as np\n",
        "import nest_asyncio\n",
        "from enum import Enum\n",
        "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
        "from fastapi.responses import StreamingResponse"
      ],
      "metadata": {
        "id": "aucIrI3tZwiJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign an instance of the FastAPI class to the variable \"app\".\n",
        "# You will interact with your api using this instance.\n",
        "app = FastAPI(title='Deploying a ML Model with FastAPI')\n",
        "\n",
        "# List available models using Enum for convenience. This is useful when the options are pre-defined.\n",
        "class Model(str, Enum):\n",
        "    yolov3tiny = \"yolov3-tiny\"\n",
        "    yolov3 = \"yolov3\"\n",
        "\n",
        "\n",
        "# By using @app.get(\"/\") you are allowing the GET method to work for the / endpoint.\n",
        "@app.get(\"/\")\n",
        "def home():\n",
        "    return \"Congratulations! Your API is working as expected. Now head over to http://localhost:8000/docs.\"\n",
        "\n",
        "\n",
        "# This endpoint handles all the logic necessary for the object detection to work.\n",
        "# It requires the desired model and the image in which to perform object detection.\n",
        "@app.post(\"/predict\") \n",
        "def prediction(model: Model, file: UploadFile = File(...)):\n",
        "\n",
        "    # 1. VALIDATE INPUT FILE\n",
        "    filename = file.filename\n",
        "    fileExtension = filename.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\")\n",
        "    if not fileExtension:\n",
        "        raise HTTPException(status_code=415, detail=\"Unsupported file provided.\")\n",
        "    \n",
        "    # 2. TRANSFORM RAW IMAGE INTO CV2 image\n",
        "    \n",
        "    # Read image as a stream of bytes\n",
        "    image_stream = io.BytesIO(file.file.read())\n",
        "    \n",
        "    # Start the stream from the beginning (position zero)\n",
        "    image_stream.seek(0)\n",
        "\n",
        "       # Write the stream of bytes into a numpy array\n",
        "    file_bytes = np.asarray(bytearray(image_stream.read()), dtype=np.uint8)\n",
        "    \n",
        "    # Decode the numpy array as an image\n",
        "    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "    \n",
        "    \n",
        "    # 3. RUN OBJECT DETECTION MODEL\n",
        "    \n",
        "    # Run object detection\n",
        "    bbox, label, conf = cv.detect_common_objects(image, model=model)\n",
        "    \n",
        "    # Create image that includes bounding boxes and labels\n",
        "    output_image = draw_bbox(image, bbox, label, conf)\n",
        "    \n",
        "    # Save it in a folder within the server\n",
        "    cv2.imwrite(f'images_uploaded/{filename}', output_image)\n",
        "    \n",
        "    \n",
        "    # 4. STREAM THE RESPONSE BACK TO THE CLIENT\n",
        "    \n",
        "    # Open the saved image for reading in binary mode\n",
        "    file_image = open(f'images_uploaded/{filename}', mode=\"rb\")\n",
        "    \n",
        "    # Return the image as a stream specifying media type\n",
        "    return StreamingResponse(file_image, media_type=\"image/jpeg\")"
      ],
      "metadata": {
        "id": "8qyUs_wDZ2KW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab에서는 로컬 호스트로 접속이 안되니 ngrok을 이용해서 임시 외부 URL로 접속하도록 변경\n",
        "\n",
        "You can use ngrok to export a port as an external url. Basically, ngrok takes something available/hosted on your localhost and exposes it to the internet with a temporary public URL.\n",
        "https://stackoverflow.com/questions/63833593/how-to-run-fastapi-uvicorn-in-google-colab"
      ],
      "metadata": {
        "id": "1a4wRE-fbef-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Allows the server to be run in this interactive environment\n",
        "#nest_asyncio.apply()\n",
        "\n",
        "# Host depends on the setup you selected (docker or virtual env)\n",
        "#host = \"0.0.0.0\" if os.getenv(\"DOCKER-SETUP\") else \"127.0.0.1\"\n",
        "\n",
        "# Spin up the server!    \n",
        "#uvicorn.run(app, host=host, port=8000)\n",
        "\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)\n"
      ],
      "metadata": {
        "id": "vxLlypKmaVRI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}